# LaDe Dataset: https://arxiv.org/abs/2306.10675

from torch.utils.data import Dataset
from .Utils import *
from tqdm import tqdm


class LaDeDataset(Dataset):
    def __init__(self,
                 graph_depth: int = 10,
                 trajs_per_graph: int = 64,
                 rotation: bool = True,
                 scaling_range: float = 0.2,
                 traj_step_mean: float = 0.1,
                 traj_step_std: float = 0.02,
                 traj_noise_std: float = 0.02,
                 traj_length: int = 128):
        """
        LaDe dataset contains road segments in 5 cities in China.
        They include Chongqing, Hangzhou, Jilin, Shanghai, and Yantai.

        This class extracts a subgraph from the road network and returns it as a tensor.

        The subgraph is generated by first selecting a random node with degree > 2,
        then growing the subgraph based on breadth-first search,
        until the graph depth is reached.

        :param graph_depth: The depth of the subgraph.
        :param min_trajs: The minimum number of trajectories simulated for each graph
        :param rotation: Whether to rotate the graph as data augmentation
        :param scaling_range: the scaling augmentation (1 - scaling_range, 1 + scaling_range)
        :param traj_step_mean: The mean distance moved in each step during traj simulation
        :param traj_step_std: The std distance moved in each step during traj simulation
        :param traj_noise_std: The std of noise applied to trajs during traj simulation
        :param traj_length: The length of output trajs after padding and truncation
        """
        # nodes: (N, 2), lat, lng
        # edges: (N, 10), 10 is the maximum degree
        # degrees: (N,), number of edges connected to each node

        _, self.nodes, self.edges, self.degrees, _ = torch.load(f"{DATASET_ROOT}/processed_roads_Shanghai.pt")
        self.nodes: Tensor = self.nodes.to(DEVICE)
        self.graph_depth = graph_depth
        self.trajs_per_graph = trajs_per_graph
        self.rotation = rotation
        self.scaling_range = scaling_range
        self.traj_step_mean = traj_step_mean
        self.traj_step_std = traj_step_std
        self.traj_noise_std = traj_noise_std
        self.traj_len = traj_length

        self.candidates = torch.where(self.degrees > 2)[0]

        self.edges = self.edges.tolist()
        self.degrees = self.degrees.tolist()
        self.candidates = self.candidates.tolist()


    def __len__(self) -> int:
        return 1_0000

    def __getitem__(self, idx):
        graph = self.getSubGraph()
        graph.normalize()
        # angle = 0 if not self.rotation else torch.rand(1) * 2 * 3.1415926
        # scale = torch.rand(1) * (self.scaling_range * 2) + 1 - self.scaling_range
        # graph.transform(angle, scale.to(DEVICE))
        trajs, paths = self.generateTrajsFromGraph(graph)
        graph_tensor = graph.toTensor()
        heatmap = self.getHeatmap(graph_tensor, trajs, 64, 64)
        return trajs, paths, graph_tensor, heatmap

    def getSubGraph(self) -> SegmentGraph:
        # select a random node with degree > 2
        random_id = random.randint(0, len(self.candidates) - 1)
        node_i = self.candidates[random_id]

        visited_edges: Set[FrozenSet[int]] = set()
        visited_nodes: Set[int] = {node_i}
        frontier: Set[int] = {node_i}
        depth: int = 0

        # use breadth-first search to find the nearest node
        while len(frontier) > 0 and depth < self.graph_depth:
            new_frontier = []
            # iterate over nodes in the frontier
            for node_id in frontier:
                # iterate over edges connected to the node
                for neighbor_id in range(self.degrees[node_id]):
                    neighbor_node_id = self.edges[node_id][neighbor_id]
                    edge = frozenset((node_id, neighbor_node_id))
                    if edge not in visited_edges:
                        visited_edges.add(edge)
                        if neighbor_node_id not in visited_nodes:
                            visited_nodes.add(neighbor_node_id)
                            new_frontier.append(neighbor_node_id)
            frontier = set(new_frontier)
            depth += 1

        subgraph = SegmentGraph()

        for edge in visited_edges:
            node_id_1, node_id_2 = list(edge)
            subgraph.append(Segment(self.nodes[node_id_1], self.nodes[node_id_2]))

        return subgraph


    def generateTrajsFromGraph(self, graph: SegmentGraph) -> Tuple[Tensor, Tensor]:
        """
        Generate trajectories from the graph.
        :param graph: the graph to generate trajectories from
        :return: N trajectories
        """
        num_segments = len(graph)
        path_len = self.graph_depth * 2 + 1

        trajectories = []
        paths = []
        for i in range(self.trajs_per_graph):
            # randomly choose a starting segment
            start_sid = random.randint(0, num_segments - 1)
            # get a random path from the graph
            path = graph.getRandomPath(start_sid)
            # simulate a trajectory
            visiting_nodes = torch.stack(path)
            trajectory = self.simulateTrajectory(visiting_nodes)
            trajectories.append(trajectory)
            paths.append(torch.nn.functional.pad(visiting_nodes, (0, 0, 0, path_len - visiting_nodes.shape[0])))

        return torch.stack(trajectories, dim=0), torch.stack(paths)


    def simulateTrajectory(self, visiting_nodes: Tensor) -> Tensor:
        """
        Simulate a trajectory by walking along the path defined by the visiting nodes.
        :param visiting_nodes: (N, 2) array of nodes to visit
        :return: (M, 2) array of the simulated trajectory
        """
        # compute the distance from the start node to each node
        pairwise_dist = torch.norm(visiting_nodes[1:] - visiting_nodes[:-1], dim=1)
        distances = torch.cumsum(pairwise_dist, dim=0)
        distances = torch.cat([torch.tensor([0], device=DEVICE), distances])

        # simulate the random walk
        walked_dist = torch.zeros(1, device=DEVICE)
        current_pos = visiting_nodes[0]
        trajectory = [current_pos]
        while walked_dist < distances[-1]:
            next_step_distance = torch.normal(torch.tensor(self.traj_step_mean), torch.tensor(self.traj_step_std))
            walked_dist += next_step_distance
            # find the position of the walker along the path
            for i in range(len(distances) - 1):
                if distances[i] <= walked_dist < distances[i + 1]:
                    current_pos = visiting_nodes[i] + (walked_dist - distances[i]) / pairwise_dist[i] * (
                            visiting_nodes[i + 1] - visiting_nodes[i])
                    break
            trajectory.append(current_pos)

        trajectory.append(visiting_nodes[-1])
        trajectory = torch.stack(trajectory)

        # simulate some GPS noise
        gps_noise = torch.randn(trajectory.shape, device=DEVICE) * self.traj_noise_std

        simulated_traj_len = len(trajectory)
        if simulated_traj_len >= self.traj_len:
            return (trajectory + gps_noise)[:self.traj_len]

        pad_size = self.traj_len - simulated_traj_len
        return torch.nn.functional.pad(trajectory + gps_noise, (0, 0, 0, pad_size))


    def getHeatmap(self, graph_tensor: Tensor, trajs: Tensor, H: int, W: int) -> Tensor:
        """

        :param graph_tensor: (N, 2, 2)
        :param trajs: (N, 128, 2)
        :param H: height of heatmap
        :param W: width of heatmap
        :return:
        """

        nodes = torch.unique(graph_tensor.view(-1, 2), dim=0)

        traj_points = trajs.view(-1, 2)
        traj_points = traj_points[torch.all(traj_points != 0, dim=1)]
        min_point, _ = torch.min(torch.cat([traj_points, nodes], dim=0), dim=0, keepdim=True)
        max_point, _ = torch.max(torch.cat([traj_points, nodes], dim=0), dim=0, keepdim=True)
        traj_points = (traj_points - min_point) / (max_point - min_point)

        nodes = (nodes - min_point) / (max_point - min_point)

        x_ids = (traj_points[:, 0] * (W - 1)).long()
        y_ids = (traj_points[:, 1] * (H - 1)).long()
        heatmap_flat = torch.zeros(H * W, dtype=torch.float32, device=DEVICE)
        flat_indices = y_ids * W + x_ids
        heatmap_flat.scatter_add_(0, flat_indices, torch.ones_like(flat_indices, dtype=torch.float32, device=DEVICE))

        x_ids = (nodes[:, 0] * (W - 1)).long()
        y_ids = (nodes[:, 1] * (H - 1)).long()
        nodesmap_flat = torch.zeros(H * W, dtype=torch.float32, device=DEVICE)
        flat_indices = y_ids * W + x_ids
        nodesmap_flat.scatter_add_(0, flat_indices, torch.ones_like(flat_indices, dtype=torch.float32, device=DEVICE))

        return torch.stack([heatmap_flat.view(H, W), nodesmap_flat.view(H, W)], dim=0)

        # max_heat, _ = torch.max(heatmap_flat, dim=0, keepdim=True)
        # max_node, _ = torch.max(nodesmap_flat, dim=0, keepdim=True)
        # return torch.stack([(heatmap_flat / max_heat).view(H, W), (nodesmap_flat / max_node).view(H, W)], dim=0)


    @staticmethod
    def collate_fn(batch_list: List[Tuple[Tensor, Tensor, List[Tensor]]]) -> Tuple[List[Tensor], List[Tensor], Tensor]:
        """
        pack data into a batch
        :param batch_list: a list of the return of LaDeDatasetCacheGenerator.__getitem__
        :return: the list of graphs, each graph is in shape (?, 2, 2). The list of lists of trajectories,
        the outer list is a batch of data, the inner list is a sample, it contains many trajs of shape (?, 2).
        """
        trajs_list, graph_list, heatmap_list = zip(*batch_list)
        return list(trajs_list), list(graph_list), torch.stack(heatmap_list, dim=0)
